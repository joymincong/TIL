{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**t-Stochastic Neighbor Embeding**\n",
    "고차원의 원공간에 존재하는 데이터 x들 간의 거리를 최대한 보존하는 저차원 y를 학습하는 방법론\n",
    "- **가정** : 가우시안 분포를 가정으로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p_{j|i} = \\dfrac{e^{-\\dfrac{|x_i - x_j|^2}{2\\sigma_i^2}}}{\\sum{e^{-\\dfrac{|x_i - x_k|^2}{2\\sigma_i^2}}}}\n",
    "$$\n",
    "-  고차원 공간에서 개체 x_i가 주어졌을 때, 개체 x_j가 선택될 확률\n",
    "\n",
    "$$\n",
    "q_{j|i} = \\dfrac{e^{-|y_i - y_j|^2}}{\\sum{e^{-|y_i - y_k|^2}}}\n",
    "$$\n",
    "-  저차원 공간에 개체 y_i가 주어졌을 때, 개체 y_j가 선택될 확률\n",
    "\n",
    "> p와 q가 최대한 작아지게 하는 만드는 것이 목표, 비슷한 지표로 `Kullback-Leibler divergence`이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습 방법**\n",
    "\n",
    "$$\n",
    "% <![CDATA[\n",
    "\\begin{align*}\n",
    "Cost&=\\sum _{ i }^{  }{ KL({ P }_{ i }||{ Q }_{ i }) } \\\\ &=\\sum _{ i }^{  }{ \\sum _{ j }^{  }{ { p }_{ j|i }\\log { \\frac { { p }_{ j|i } }{ { q }_{ j|i } }  }  }  }\n",
    "\\end{align*} %]]>\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습 속도 향상**\n",
    "$\\sigma$는 데이터 밀도 차이로 생기는 확률 왜곡을 방지하는 값이다. 하지만 반복 실험 결과 시 큰 차이가 없었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{ p }_{ ij }=\\frac { { p }_{ j|i }+{ p }_{ i|j } }{ 2 } ,\\quad { q }_{ ij }=\\frac { { q }_{ j|i }+{ q }_{ i|j } }{ 2 }\n",
    "$$\n",
    "- 다음과 같이 다시 쓸수 있다.\n",
    "\n",
    "$$\n",
    "% <![CDATA[\n",
    "\\begin{align*}\n",
    "Cost&=\\sum _{ i }^{  }{ KL({ P }_{ i }||{ Q }_{ i }) } \\\\ &=\\sum _{ i }^{  }{ \\sum _{ j }^{  }{ { p }_{ ij }\\log { \\frac { { p }_{ ij } }{ { q }_{ ij } }  }  }  } \\\\ \\frac { \\partial C }{ \\partial { y }_{ i } } &=4\\sum _{ j }^{  }{ ({ y }_{ j }-{ y }_{ i })({ p }_{ ij }-{ q }_{ ij }) }\n",
    "\\end{align*} %]]>\n",
    "$$\n",
    "\n",
    "- 그래디언트 디센트 방식으로 $y_i$를 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crowding Problem**\n",
    "적당히 떨어져 있는 이웃 j 와 많이 떨어져 있는 이웃 k 가 선택될 확률이 크게 차이 나지 않는 문제.\n",
    "\n",
    "이 문제를 해결하기 위해 가우시안 분포 대신에 t-분포를 사용한다. q에 대해서만 t-분포로 사용\n",
    "\n",
    "$$\n",
    "{ q }_{ ij }=\\frac { { (1+{ \\left| { y }_{ i }-{ y }_{ j } \\right|  }^{ 2 }) }^{ -1 } }{ \\sum _{ k\\neq l }^{  }{ { (1+{ \\left| { y }_{ k }-{ y }_{ l } \\right|  }^{ 2 }) }^{ -1 } }  }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
