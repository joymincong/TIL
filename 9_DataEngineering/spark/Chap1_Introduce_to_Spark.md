# Chapter 1. 스파크를 이용한 데이터 분석 소개

## 1-1. 아파치 스파크란?

- 빠른 속도를 위한 클러스터용 연산 플랫폼
- 맵 리듀스 모델을 다양한 형태로 작업
  - 대화형 명령어 쿼리
  - 스트리밍 처리
  - 배치 애플리케이션
  - 반복 알고리즘
- 쉽운 접근
  - 파이썬, 자바, 스칼라, SQL API
  - Hadoop 클러스터 실행, Cassandra 데이터 소스 접근 가능



## 1-2. 통합된 구성

- 여러 컴포넌트로 구성
- 다수의 클러스터 위에서 돌아가는 연산 프로그램 스케쥴링 및 분배 감시 역활
  - 장점 : 서로 다른 모델을 하나로 합쳐, 유지 보수가 쉽다.
  - **클러스터와 노드**
    - 클러스터 : 여러 노드의 집합, 작업 단위
    - 노드 : 클러스터의 구성원
-  구성 : 스파크 코어 (스파크 SQL + 스파크 스트리밍 + MLlib + 그래프 X + 클러스터 매니져)



### 1-2-1. 스파크 코어

- 작업 스케쥴링, 메모리 관리, 장애 복구, 저장 장치 연동 
- RDD(resilient Distributed Dataset)를 정의하는 API의 기반으로 구성
  - **RDD** : 여러 노드를 병렬처리 할 수 있는 아이템들의 모음



### 1-2-2. 스파크 SQL

- 정형 데이터를 처리하기 위한 스파크 패키지
- 하이브 테이블, 파케이, JSON 다양한 데이터 소스 지원
- SQL, HQL를 이용한 질의
- RDD에서 제공하는 코드를 SQL쿼리와 함께 사용이 가능



### 1-2-3. 스파크 스트리밍

- 실시간 데이터 스트림이 가능해 주는 컴포넌트
- RDD API와 일치하여 디스크 저장데이터, 스트림 데이터 상관없이 바꿔가면 사용이 가능



### 1-2-4. MLlib

- 머신러닝 라이브러리 (회귀, 분류, 클러스터링, 협업 필터링)
- 모델 평가, 외부 데이터 불러오기 가능



### 1-2-5. 그래프X

- 그래프를 다루기 위한 라이브러리



### 1-2-6. 클러스터 매니저

- 한 노드에서 수천 노드까지 효과적으로 성능을 확장할 수 있도록 제작
- Hadoop의 YARN, 아파치 메소스, 스파크 단독 스케쥴러 등 다양한 클러스터 매니저에서 동작 가능 



## 1-3. 역활별 스파크 사용 방법

**데이터 과학**

- 스파크 셀, 스파크 SQL 등 대화형 쉘을 이용한 데이터 분석
- MLlib을 이용한 데이터 분석



**데이터 엔지니어**

- 클러스터 위에 동시에 작동할 수 있도록 개발을 도와준다.



## 1-4. 스파크 역사

- 2009년 : UC버클리 RAD 연구실의 연구 프로젝트로 진행 
  - 하둡 맵리듀스의 반복적인 대화형에 취약
  - 인메모리 저장 장치 및 효과적 복구 지원등 대화형 쿼리와 반복성 알고리즘 개선을 목적으로 개발
- 2010년 3월 : 오픈소스화
- 2011년 : AMPLab은 샤크, 스파크 스트리밍등 고수준 컴포넌트 개발
- 2013년 : 아파치에 인수



## 1-5. 스파크 버전

- 스파크 1.0 : 2014년 5월
- 현재 스파크 1.1



## 1-6. 스파크의 저장소 계층

- HDFS (Hadoop Disrtibuted Filesystem), 하둡API를 지원하는 저장 시스템 (AWS S3, 카산드라, 하이브, HBase)등 다양한 분산 데이터 모음 생성 가능.

- 반드시 하둡이 필요하지 않음.

- Text file, Squence file, 에이브로, 파케이 지원

  ​